**Proposal to invest**

**in Metaverse Vitual Estate**

\- through machine learning and real estate data analysis -

![그림1](https://user-images.githubusercontent.com/102775009/161194994-24e52382-44cc-4354-b47c-916b5720904f.png)

# **Contents** {#contents .TOC-Heading}

1\. Purpose 3

2\. Results & Interpretation 4

3\. Analysis Correlation 5

4\. Clustering 6

5\. DNN 8

6\. Mini Essay 10

**\
**

**1. purpose**

Our project analyzed the concurrent estate prices of South Korea and
applied them in the virtual real estate space. With the upcoming rise of
popularity of the virtual real estate industry, more demand would mean
less supply. This being said, our application and analysis will be
crucial as virtual real estate prices heavily depend on rarity and the
demand and supply of the virtual land itself. We firmly believe that our
analysis of the concurrent market applied in the virtual real estate
situations could also be used as an efficient guideline when applied in
other real-world, metaverse situations.


**2. Results & Interpretation**

The first process to run to proceed with correlation, clustering, and
deep neural networks was Excel\'s data preprocessing. Data preprocessing
was carried out with independent variables (X = 44 variables) and
dependent variables (Y = 227 data points). The correlation analysis was
carried out because it was necessary to know how closely the current
real estate price index and each label (1,2,3) value of the meta-bus
were related to the remaining 42 variables.

First, to explain the label value in the metaverse virtual in the
metaverse virtual world, it is as follows.

Land Class 1: Land class one tiles are the first 100k tiles sold in a
country. These pay the most tax compared to any other land class.

Land Class 2: Land class two tiles are tiles bought between 100k to 300k
tiles bought in a country. They still pay a good amount of tax however
not as much as land class one.

Land Class 3: Land class three tiles are tiles bought between 300k to
500k tiles bought in a country. They give a small account of Land tax
compared to class one.

- data -
![그림10](https://user-images.githubusercontent.com/102775009/161195147-bbec13fd-ad23-4de3-a72e-906b86f7a01f.png)
![그림11](https://user-images.githubusercontent.com/102775009/161195148-f5723ef1-215d-45ae-8002-d6ddfa7c998d.png)


**\
**

**3. Correlation Analysis**

In the correlation analysis we used the pearson method. As a result, a
graph of correlation analysis for covariance and a graph of p-value were
obtained.

The following graph is a graph for covariance and p-value.

![그림2](https://user-images.githubusercontent.com/102775009/161195562-93c7405f-1605-4245-be36-48ca2bd36103.png)![그림3](https://user-images.githubusercontent.com/102775009/161195126-cc353b67-c951-4758-a54c-15b45c9be612.png)

\<P-value Graph\> \<Covariance Graph\>

> First of all, if you look at the p-value graph above, it mostly
> consists of values less than 0.05. This means that anything lower than
> 0.05 is highly correlated. There were only a few things that were
> really irrelevant. The variables not related to the metaverse minority
> were health level awareness and the number of lodging establishments.
> We found that the p-value of the health level recognition rate was
> 0.91, which was completely irrelevant.

Next is the covariance graph. This is a covariance graph, showing
positive correlations and negative correlations such as +1/-1. Simply,
if the value is closer to absolute value 1, it means that variable is
more correlated with independent variable X. We found that the variables
with the highest absolute value had the greatest correlation with the
welfare budget ratio, the death toll, the ratio of the elderly living
alone, the average real estate price index, the number of religions, and
the number of cultural facilities.

Before we use deep neural network, we use cluster analysis with the data
that had been subjected to correlation analysis. The reason why use
cluster analysis was to find out which variables are grouped, and which
variables are identified by outlier detection.

**4. Clustering**

![그림5](https://user-images.githubusercontent.com/102775009/161195176-29842211-6cb9-409a-8fd4-daa7113a0f7f.png)

When performing cluster analysis,
according to Elbow k-means clustering, it was ideal to divide the
cluster into six groups.

The float type of the array shown next graph is 32, and the first to 227
datasets mean regions. The cluster was divided int 6 cluster, cluster 0,
cluster 1, cluster 2, cluster 3, cluster 4, cluster 5. For
visualization, each cluster was classified into which region it belongs
to.

**Visualization**

![그림6](https://user-images.githubusercontent.com/102775009/161195191-43af43e9-9765-4c40-856f-3cee791c8139.png)

Cluster 0: Purple Cluster 0 is close to label 3 in the metaverse,
according to the weights and Cluster 5 is close to label 1 in the
metaverse.

Cluster 1: Blue

Cluster 2: Green

Cluster 3: Yellow

Cluster 4: Orange

Cluster 5: Red

Results: We have to investigate the red cluster.

Rather than ending with cluster analysis, we use a deep neural network
to set 159 regional data for label weights as train_set, and use the
remaining ratio 3 as test_set to find out how many weights are in the
weight values within 0 to 12.

**5. DNN**

![그림7](https://user-images.githubusercontent.com/102775009/161195198-a158cf0c-f089-429a-868f-1f3acb261dc4.png)

It consists of one input layer, two hidden layers, and one output layer.
The hidden layer\'s sense is set to 12, and the input shape is set to
43.![그림8](https://user-images.githubusercontent.com/102775009/161195214-fdd11369-0bf1-49d3-beb2-19cffd75f3d1.png)

Of the 227 data, 159 were classified as training sets and the rest as
test sets. Y_test\[0\] refers to the 0th data in the test set. We put
test data in X_new to input data, which shows that each y_ped is
perfectly consistent. This indicates that the model is good from the
point data of the test set (label = 11.4).

![그림9](https://user-images.githubusercontent.com/102775009/161195221-50830870-e705-4ff5-8332-3acd2c0fd387.png)

Without early stopping, the validation loss increases near the 90th
epoch. To prevent overfitting, it is effective to stop epoch early to
90.

**6. Mini-essay**

we had a lot of difficulties in processing 44 data attributes and a
total of over 9,000 data. The sale price of tiles in virtual space was
what each seller had priced themselves for. So the price gap was huge
for no reason.

However, we analyzed the correlation by segmenting the class and
labeling it, and it was successful. So it was difficult to find the
relationship between virtual space and real estate land prices, but we
made sure to understand correction, clustering, and DNN by
pre-processing data and compiling code one by one.
